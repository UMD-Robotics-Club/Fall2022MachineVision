{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my solutions for the 3 challenge problems given in getting started.ipynb:\n",
    "Just a note that since I'm usingthe os library for some of these solutions they may not work on mac or linux computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording a video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished recording\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "vid_name = 'output.avi'\n",
    "\n",
    "# open up a video capture from the first available webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# start video recording to a file\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# args: file name, fourcc, playback fps, frame size\n",
    "out = cv2.VideoWriter(vid_name, fourcc, 60.0, (640, 480))\n",
    "\n",
    "# begin recording\n",
    "while cap.isOpened():\n",
    "    # get a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # if a frame couldn't be retrieved, exit the program\n",
    "    if not ret:\n",
    "        break\n",
    "    # write the frame to the output file\n",
    "    out.write(frame)\n",
    "\n",
    "    # display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # write the frame to the output file\n",
    "    out.write(frame)\n",
    "\n",
    "    # allow the user to press q to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# stop recording\n",
    "cap.release()\n",
    "# close the video file\n",
    "out.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Finished recording\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting a Video to a folder of frame snap shots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# the path to the video file\n",
    "vid_path = 'output.avi'\n",
    "# the path to the output frame folder\n",
    "image_folder_path = 'output_images'\n",
    "# only extract every 10th frame\n",
    "num_skip_frames = 10\n",
    "\n",
    "# create the output folder if it doesn't exist\n",
    "if not os.path.exists(image_folder_path):\n",
    "    os.makedirs(image_folder_path)\n",
    "\n",
    "# open a video file\n",
    "cap = cv2.VideoCapture(vid_path)\n",
    "\n",
    "# export every fifth frame to an image\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    # get a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # if a frame couldn't be retrieved, exit the program\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # export every fifth frame\n",
    "    if frame_count % num_skip_frames == 0:\n",
    "        # write the frame to an image\n",
    "        cv2.imwrite(f'{image_folder_path}/frame_{frame_count}.jpg', frame)\n",
    "\n",
    "    # increment the frame count\n",
    "    frame_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split a folder full of images randomly into a training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from random import random\n",
    "\n",
    "# the path to the folder containing the images\n",
    "source_folder_path = 'output_images'\n",
    "# the path to the folder that you would like to have the validion iamges copied to\n",
    "validation_path = 'output_images/validation'\n",
    "# the path to the folder that you would like to have the training iamges copied to\n",
    "training_path = 'output_images/training'\n",
    "# the percentage of images to use for validation\n",
    "validation_percent = 0.3\n",
    "\n",
    "# create the validation and training folders\n",
    "os.makedirs(validation_path, exist_ok=True)\n",
    "os.makedirs(training_path, exist_ok=True)\n",
    "\n",
    "# get a list of all the files in the source folder\n",
    "files = os.listdir(source_folder_path)\n",
    "\n",
    "# iterate over all the files and copy validation_percent of them to the validation folder\n",
    "for file in files:\n",
    "    try:\n",
    "        if random() < validation_percent:\n",
    "            shutil.copy(f'{source_folder_path}/{file}', validation_path)\n",
    "        else:\n",
    "            shutil.copy(f'{source_folder_path}/{file}', training_path)\n",
    "    except PermissionError:\n",
    "        print(f'Permission denied for {file}')\n",
    "        print(\"Continuing anyways...\")\n",
    "    except IsADirectoryError:\n",
    "        pass\n",
    "    except FileNotFoundError:\n",
    "        print(f'File not found for {file}')\n",
    "        print(\"Copying next file\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully your solutions are similar to these. If they aren't, that's okay. Take some time to review and refine your solutions and feel free to reference these solutions if you get stuck.\n",
    "\n",
    "# Setting up labelIMG\n",
    "With the first few tools we can now create a set of images and export them to a training and validation folder. We now need to be able to label the images so that our machine learning model will know what it's looking at while it's training. This is where labelIMG[https://github.com/heartexlabs/labelImg] comes into play. This is a tool that allows you to label images with bounding boxes. It's a little tricky to set up, but once you do it's pretty easy to use. Here's how to set it up:\n",
    "\n",
    "- Step 1: Deactivate your virtual enviroment. labelIMG doesn't play well with virtual enviroments for some reason. I've had greater sucess setting it up in the main python enviroment. You can deactivate the viertual enviroment by typing `deactivate` in the terminal.\n",
    "\n",
    "- Step 2: Download the labelIMG repo as a .zip file and extract it into this repository. In the integrated VS code terminal change directories to the labelImg-master folder. `cd labelImg-master`\n",
    "\n",
    "- Step 3: Follow the instalation steps for labelImg on the github page that you downloaded that repo from. The steps are pretty straight forward, but if you ahve questions, let me know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Training Data\n",
    "With labelIMG set up you are now ready to start gathering data. Our goal is to train the YOLOv5 model to detect the 5 yellow numbers that we have. Since labeling all of the data for this will be very time consuming, pelase start by gathering data of only one of the numbers. Talk to Quinn about which number you should record because we will try to split the work up evenly.\n",
    "\n",
    "With a number chosen, use your phone to record video of the number. Make sure to get video of the number from all angles. There should be at least 20 seconds of video of the number before you're done. Transfer that video to the folder this repository is in and use your \"Exporting video to frames\" programming solution to export the video to frames. You should have around 100 frames exported total. If you have more than that, increase the number of frames you skip before exporting the next frame.\n",
    "\n",
    "From here, use labelIMG to label the images. LabelIMG has a very good tutorial on how to use it on its github repo. If you have questions about data collection or labeling please ask Quinn. The model is very sensitive to incorrect data and labeling and will pick up on any patterns that you give it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('fallVenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d07961b51e3ba144781993c9ab4bff2eb4315dba5f9acbd3dbd108d95dd11f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
