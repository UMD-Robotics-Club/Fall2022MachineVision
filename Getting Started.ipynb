{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello Everyone! Now that you have Jupyter notebooks installed you are in the right place! Jupyter notebooks are an awesome way to create interactive python scripts and write down your thoughts while your at it. In this file we'll be going over how to get started with retraining yolov5 on your own custom dataset.\n",
    "\n",
    "# Preparing this Repository\n",
    "This repository requires the yolov5 repository to be copy-pasted into it in order to work. Go ahead and download the yoloV5 github repo and paste it in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a virtual enviroment\n",
    "Virtual enviroments are really important for any python programmer to know. THey allow you to have multiple versions of python installed on your computer and switch between them. This is really important for this project because we need to install a specific version of pytorch and torchvision. If you don't use a virtual enviroment you will have to uninstall your current version of pytorch and torchvision and install the specific version we need. This is a pain and can cause a lot of problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a virtual enviroment we will use the command\n",
    "\n",
    "```bash\n",
    "python -m venv fallVenv\n",
    "```\n",
    "(for some people you will have to use the command py instead of python. You know who you are.)\n",
    "\n",
    "You can fill in whatever you want for the name of the virtual enviroment.  I will use \"fallVenv\" for this tutorial and strongly recommend you do the same. Now that we have created our virtual enviroment we need to activate it. To do this we will use the command\n",
    "\n",
    "```bash\n",
    "fallVenv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "For the first time you run this command this often gives an error that scripts aren't allowed by your administrative policy. You'll have to google that error message and the first stack overflow link should tell you how to fix it.\n",
    "\n",
    "We will also need to reinstall the packages for our virtual enviroment. Change directories to the yolov5 folder and run the command\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Finally, in this jupyter ntoebook, in the top right-hand corner you will see some text that says something along the lines of Python 3.9.13 64-bit. Click on that and select the fallVenv that you just created. This will make sure that you are using the correct version of python in this jupyter notebook.\n",
    "\n",
    "That's all there is to it! Your virtual enviroment is now installed! Let me know when you're finished so we can move onto the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\quinn/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-14 Python-3.9.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 480x640 3 persons\n",
      "Speed: 8.6ms pre-process, 926.1ms inference, 2.1ms NMS per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# this script may take a while to finish\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# get an image fro mthe webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "# make sure a frame was actually returned\n",
    "if not ret:\n",
    "    exit()\n",
    "\n",
    "# convert the image to RGB\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load the yolov5 model with torch\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# run the model on the frame\n",
    "results = model(frame)\n",
    "\n",
    "# show the results\n",
    "results.print()\n",
    "results.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a great starting place on how to use YOLOv5 in your own python scripts. There's more stuff that needs to be done to improve it, but it works right?\n",
    "\n",
    "# Training YOLOv5 on your own dataset\n",
    "This is where you actaully get to start doing your own thing. My challenge to you is to create the reuired scripts in a jupyter notebook in order to:\n",
    "\n",
    "- Take a video and save it to a file\n",
    "- Take a video file and export it to image frames\n",
    "- Take a folder of images and randomly split it into a training and validation set\n",
    "\n",
    "OpenCV will be the library you need in order to do the first two steps and os is the library to do the last step. Go ahead and create a new branch on this repository titled \"yourname-trainingData\" and switch to that branch to begin programming. I'll be here if you have any questions on how to get started. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n",
      "15\n",
      "['frame0.jpg', 'frame1.jpg', 'frame10.jpg', 'frame11.jpg', 'frame13.jpg', 'frame15.jpg', 'frame16.jpg', 'frame17.jpg', 'frame18.jpg', 'frame19.jpg', 'frame2.jpg', 'frame20.jpg', 'frame21.jpg', 'frame22.jpg', 'frame23.jpg', 'frame25.jpg', 'frame26.jpg', 'frame28.jpg', 'frame29.jpg', 'frame3.jpg', 'frame31.jpg', 'frame32.jpg', 'frame35.jpg', 'frame36.jpg', 'frame37.jpg', 'frame38.jpg', 'frame39.jpg', 'frame4.jpg', 'frame40.jpg', 'frame41.jpg', 'frame42.jpg', 'frame44.jpg', 'frame45.jpg', 'frame46.jpg', 'frame47.jpg', 'frame5.jpg', 'frame51.jpg', 'frame52.jpg', 'frame53.jpg', 'frame54.jpg', 'frame55.jpg', 'frame56.jpg', 'frame57.jpg', 'frame6.jpg', 'frame60.jpg', 'frame61.jpg', 'frame62.jpg', 'frame63.jpg', 'frame64.jpg', 'frame65.jpg', 'frame66.jpg', 'frame67.jpg', 'frame68.jpg', 'frame7.jpg', 'frame70.jpg', 'frame71.jpg', 'frame72.jpg', 'frame73.jpg', 'frame74.jpg', 'frame8.jpg', 'frame9.jpg']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Capture video and save\n",
    "vid = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  \n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))  \n",
    "  \n",
    "while(vid.isOpened()):  \n",
    "    ret, frame = vid.read()  \n",
    "    if ret==True:\n",
    "        # * could flip video?  \n",
    "        # * frame = cv2.flip(frame,0)  \n",
    "  \n",
    "        # write the frame  \n",
    "        out.write(frame)  \n",
    "  \n",
    "        cv2.imshow('frame',frame)  \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  \n",
    "            break  \n",
    "    else:  \n",
    "        break  \n",
    "  \n",
    "# Release everything if job is finished  \n",
    "vid.release()  \n",
    "out.release()  \n",
    "cv2.destroyAllWindows()  \n",
    "\n",
    "# extract video to image frames\n",
    "vidread = cv2.VideoCapture('output.avi')\n",
    "success,image = vidread.read()\n",
    "count = 0\n",
    "while success:\n",
    "  cv2.imwrite(os.path.join('C:/Users/whoos/Desktop/Fall-22/Robotics/Fall2022MachineVision/Frames/', 'frame' + str(count) + '.jpg'), image)     # save frame as JPEG file\n",
    "  success, image = vidread.read()\n",
    "  print('Read a new frame: ', success)\n",
    "  count += 1\n",
    "\n",
    "vidread.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# random split\n",
    "delete = True\n",
    "\n",
    "source = 'C:/Users/whoos/Desktop/Fall-22/Robotics/Fall2022MachineVision/Frames/'\n",
    "dest1 = 'C:/Users/whoos/Desktop/Fall-22/Robotics/Fall2022MachineVision/fallVenv/data/Training'\n",
    "dest2 = 'C:/Users/whoos/Desktop/Fall-22/Robotics/Fall2022MachineVision/fallVenv/data/Validation'\n",
    "only_files = [f for f in os.listdir(source) if os.path.isfile(os.path.join(source, f))]\n",
    "no_of_files = round((len(only_files)/5))\n",
    "\n",
    "print(no_of_files)\n",
    "\n",
    "for i in range(no_of_files):\n",
    "    random_file=random.choice(os.listdir(source))\n",
    "    source_file=\"%s/%s\"%(source,random_file)\n",
    "    dest_file=dest1 + '/' + random_file\n",
    "    destination_for_file = open(dest_file,'wb+')\n",
    "    source_for_file = open(source_file,'rb')\n",
    "    destination_for_file.write(source_for_file.read())\n",
    "    destination_for_file.close()\n",
    "    source_for_file.close()\n",
    "    \n",
    "    if delete:\n",
    "        os.remove(source_file)\n",
    "    \n",
    "files_left = [j for j in os.listdir(source) if os.path.isfile(os.path.join(source, j))]\n",
    "\n",
    "print(files_left)\n",
    "\n",
    "for k in range(len(files_left)):\n",
    "    list_file = random.choice(os.listdir(source))\n",
    "    source_file=\"%s/%s\"%(source, list_file)\n",
    "    dest_file=dest2 + '/' + list_file\n",
    "    destination_for_file = open(dest_file,'wb+')\n",
    "    source_for_file = open(source_file,'rb')\n",
    "    destination_for_file.write(source_for_file.read())\n",
    "    destination_for_file.close()  \n",
    "    source_for_file.close()\n",
    "\n",
    "    if delete:\n",
    "        os.remove(source_file)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame12.jpg', 'frame14.jpg', 'frame24.jpg', 'frame27.jpg', 'frame30.jpg', 'frame33.jpg', 'frame34.jpg', 'frame43.jpg', 'frame48.jpg', 'frame49.jpg', 'frame50.jpg', 'frame58.jpg', 'frame59.jpg', 'frame69.jpg', 'frame75.jpg']\n",
      "['frame0.jpg', 'frame1.jpg', 'frame10.jpg', 'frame11.jpg', 'frame13.jpg', 'frame15.jpg', 'frame16.jpg', 'frame17.jpg', 'frame18.jpg', 'frame19.jpg', 'frame2.jpg', 'frame20.jpg', 'frame21.jpg', 'frame22.jpg', 'frame23.jpg', 'frame25.jpg', 'frame26.jpg', 'frame28.jpg', 'frame29.jpg', 'frame3.jpg', 'frame31.jpg', 'frame32.jpg', 'frame35.jpg', 'frame36.jpg', 'frame37.jpg', 'frame38.jpg', 'frame39.jpg', 'frame4.jpg', 'frame40.jpg', 'frame41.jpg', 'frame42.jpg', 'frame44.jpg', 'frame45.jpg', 'frame46.jpg', 'frame47.jpg', 'frame5.jpg', 'frame51.jpg', 'frame52.jpg', 'frame53.jpg', 'frame54.jpg', 'frame55.jpg', 'frame56.jpg', 'frame57.jpg', 'frame6.jpg', 'frame60.jpg', 'frame61.jpg', 'frame62.jpg', 'frame63.jpg', 'frame64.jpg', 'frame65.jpg', 'frame66.jpg', 'frame67.jpg', 'frame68.jpg', 'frame7.jpg', 'frame70.jpg', 'frame71.jpg', 'frame72.jpg', 'frame73.jpg', 'frame74.jpg', 'frame8.jpg', 'frame9.jpg']\n"
     ]
    }
   ],
   "source": [
    "# clear data\n",
    "source1 = 'C:/Users/whoos/Desktop/Fall-22/Robotics/Fall2022MachineVision/fallVenv/data/Training'\n",
    "source2 = 'C:/Users/whoos/Desktop/Fall-22/Robotics/Fall2022MachineVision/fallVenv/data/Validation'\n",
    "\n",
    "files_left = [j for j in os.listdir(source1) if os.path.isfile(os.path.join(source1, j))]\n",
    "\n",
    "print(files_left)\n",
    "\n",
    "delete = True\n",
    "\n",
    "for k in range(len(files_left)):\n",
    "    list_file = random.choice(os.listdir(source1))\n",
    "    source_file=\"%s/%s\"%(source1, list_file)\n",
    "    source_for_file = open(source_file,'rb')\n",
    "    source_for_file.close()\n",
    "\n",
    "    if delete:\n",
    "        os.remove(source_file) \n",
    "\n",
    "files_left = [j for j in os.listdir(source2) if os.path.isfile(os.path.join(source2, j))]\n",
    "\n",
    "print(files_left)\n",
    "\n",
    "for k in range(len(files_left)):\n",
    "    list_file = random.choice(os.listdir(source2))\n",
    "    source_file=\"%s/%s\"%(source2, list_file)\n",
    "    source_for_file = open(source_file,'rb')\n",
    "    source_for_file.close()\n",
    "\n",
    "    if delete:\n",
    "        os.remove(source_file)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fallVenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "657da657c5bb02beb96aab512ec23405b6da4ba9ca3bb3200f0360b84e90dc1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
